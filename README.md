# Textmining_R
> 
# 국회회의록 문서를 통한 텍스트마이닝
> 텍스트 데이터를 통한 정당 분류기 구축


국회의원들의 발언 데이터를 통한 분류모델 작성 과정이다. 연세대학교 송 민 교수가 2012년에 작성한 '텍스트 마이닝을 활용한 신문사에 따른 내용 및 논조 차이점 분석'의 프로세스를 동일하게 따라갔다. 이번 모델은 '패스트트랙'과 관련한 정당의 발언을 기준으로 작성했다. 논란이 있던 지난 기간의 법제사법위원회 회의록을 토대로 전처리, 모델링, 분류 등의 과정을 거쳤다.

## 국회회의록 데이터

![](/image/국회회의록.png)

데이터 출처:
> 국회회의록 사이트 내에서 문서화된 회의록 데이터를 다운로드 하였음. 특정 이슈를 고려해 해당 기간 내의 회의록만 다운로드. 법제사법위원회의 10회, 11회 회의록을 다운로드.

## 전처리
![](/image/전처리.png)

전처리 과정:
> PDF 파일은 전처리에 어려움이 있어 HWP로 다운로드 한 파일을 txt로 재저장한 파일을 시작데이터로 사용. 국회회의록 사이트 내에서 문서화된 회의록 데이터를 다운로드. 특정 이슈를 고려해 해당 기간 내의 회의록만 다운로드. PDF 파일은 전처리에 어려움이 있어 HWP로 다운로드 한 파일을 txt로 재저장한 파일을 분석 데이터로 사용.


## 시각화

![](/image/시각화_1.png)

시각화 관련_1:
> 각 정당 별 주요 단어를 정렬. 그래프로 보기좋게 나열

> 더불어민주당은 주로 '문제', '자유한국당', '방해' 등의 단어가 있는 것으로 보아 '자유한국당이 방해하고 문제'라고 보는 듯하다.
> 자유한국당은 '오늘', '우리', '때문', '오신환' 등으로 보아 '오늘 회의가 우리 때문에 안 되는 거냐'와 '오신환 의원한테 발언권 달라' 는 내용을 많이 언급한 듯하다.
> 바른미래당은 '발언권', '불법', '존경' 등으로 보아 '발언권을 달라'(오신환 의원이 사보임 때문에 발언권 잃었음)는 것과 '패스트트랙이 불법'이라는 것을 어필한 듯 하다.
> 마지막으로 정의-민주평화(교섭단체, 실질적으로 이 회의에서는 민주평화만 있었음)당은 특색이 없다. 발언 데이터도 3문단만 있다. 어느 당에도 눈총 안 받고 끝내고 싶었던 걸까.

![](/image/시각화_2.png)

워드클라우드:
> 위 그래프를 워드클라우드로 바꿔보았다. 정작 보기는 어렵다.


## 코사인 유사도 분석
![](/image/코사인유사도.png)

코사인유사도 분석:
> 거리 기준으로 비교하려는 종속변수와 멀고-가까운 비교값을 찾는 과정. 여기서는 말도 안 되는 결과가 나왔다. 왜냐하면! 애초에 차원의 양이 유사하지 않기 때문이다. 더불어민주당이랑 자유한국당이 말을 제일 많이 했다. 그래서 차원도 두 집단이 제일 많다. 그러니까 뭘 해도 저 집단과 가까운 것이다. 차원의 양이 유사했으면 다른 결과를 얻었을 것 같다.


## 모델링 - 나이브베이즈
![](/image/훈련.png)

훈련 데이터:
> 나이브베이즈로 모델링 후, 훈련 셋을 넣었다. 결과는 놀랍다. 매우 낮다. 단순히 양의 문제보다도 각 정당의 특성을 도드라지게 하는 단어를 구분할 수 있어야 하기 때문이다. TF-IDF로 수치가 높은 단어만 선별해서 모델링하면 다른 결과가 나왔을 수도 있다. 하지만 송 민 교수의 논문도 우선 그대로 진행했기에(변명) 나도 그렇게 진행했다.


![](/image/평가.png)

평가 데이터:
> 말해 무엇하리. 심지어 민주평화-정의당은 자기 집을 하나도 못 찾아갔다. 말이라도 많이 했으면...


## 결론-마무리

> 송민 교수의 논문 흐름을 따라 다른 주제를 유사하게 진행해보았다. '패스트트랙' 이슈를 기반으로 국회의원들의 발언 데이터로 정당 분류 작업을 위한 과정을 진행했다. '전처리-시각화-모델링-검증'의 과정으로 해당 이슈를 다루었다.
>
> 모델링 과정에서 아쉬움이 남았다. 크게 원인은 2개로 생각한다. 1차적으로는 데이터의 양적 문제. '패스트트랙'과 관련한 회의록이 2건 뿐이라 분석하기 위한 데이터의 양이 적었다. 그 과정에서 더불어민주당과 자유한국당에 비해 바른미래, 정의-민주평화당의 발언 데이터가 압도적을 차이났다. 그 결과가 '코사인유사도' 분석에 그대로 반영된 것이라 생각한다.
>
> 2차적으로는 어절 단위의 분석이었다. TF-IDF, LDA 등의 과정을 전혀 거치지 않은 채, 어절 단위로 차원을 분류해서 진행했다. 문서 별 각 단어의 weight를 파악한 후에 weight가 높은 단어만 선별하거나, 특정 이슈(단어)와 관련된 단어를 묶어서 진행했다면 좀 더 의미있는 결과가 나왔을 수도 있다. 물론 전제는 데이터가 많을 때 가능한 일이다...^^;;